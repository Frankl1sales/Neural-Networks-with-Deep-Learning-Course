{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iafPdtuncbq7"
   },
   "source": [
    "<h2><center>MNIST classification using <i>LeNet5</i></center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4VrCB5La5rD"
   },
   "source": [
    "# Importing Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlKZ3Hnas7B4",
    "outputId": "f55521fc-5970-4e03-cb0e-13b513ad3c6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow version 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras main module forcing tensorflow 1.x backend\n",
    "import tensorflow as tf\n",
    "#import keras\n",
    "print(\"Using tensorflow version \" + str(tf.__version__))\n",
    "#print(\"Using keras version \" + str(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_QLz9_jbRZq"
   },
   "source": [
    "# Loading and preparing the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gG83hGyVmijn",
    "outputId": "d8e02bce-a737-4d90-bce4-6711c78c3990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "# The MNSIT dataset is ready to be imported from Keras into RAM\n",
    "# Warning: you cannot do that for larger databases (e.g., ImageNet)\n",
    "#from keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)\n",
    "#!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "x5VAu7oW0Zu4",
    "outputId": "a5373fee-54a8-4bd6-eed1-a4a7329ed7b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for 0-th train image is: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe4437f0a60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let us visualize the first training sample using the Gnuplot library\n",
    "from matplotlib import pyplot as plt\n",
    "imageIndex = 0\n",
    "print(\"Label for \" + str(imageIndex) + \"-th train image is: \" + str(train_labels[0]))\n",
    "plt.imshow(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQbkllF8mnaf",
    "outputId": "b43bfaf0-4460-4b3f-d5d6-c54a41d7dc3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the native 0-th train label: 5\n",
      "This is the one-hot encoding of the 0-th train label: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Do you remember about one-hot encoding ?\n",
    "#from keras.utils.np_utils import to_categorical\n",
    "import copy\n",
    "\n",
    "ori_test_labels=copy.deepcopy(test_labels)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "imageIndex = 0\n",
    "print(\"This is the native \" + str(imageIndex) + \"-th train label: \" + str(train_labels[0]))\n",
    "train_labels = to_categorical(train_labels)\n",
    "print(\"This is the one-hot encoding of the \" + str(imageIndex) + \"-th train label: \" + str(train_labels[0]))\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptTRSDo5nJyZ",
    "outputId": "9d8f16b1-a2c8-47aa-acce-06b9033103b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: (60000, 28, 28, 1)\n",
      "test_images shape: (10000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Reshape to proper images with 1 color channel according to backend scheme\n",
    "img_rows, img_cols = train_images.shape[1], train_images.shape[2]\n",
    "train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols,1 )\n",
    "print('train_images shape:', train_images.shape)\n",
    "print('test_images shape:', test_images.shape)\n",
    "print(train_images.shape[0], 'train samples')\n",
    "print(test_images.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "# Normalize the images so that have zero mean and unitary deviation wrt the train set\n",
    "train_mean = train_images.mean()\n",
    "train_std = train_images.std()\n",
    "\n",
    "train_images = (train_images - train_mean)/train_std\n",
    "test_images = (test_images - train_mean)/train_std\n",
    "\n",
    "# Alternatively, we could normalize the image in the [0-1] range instead\n",
    "#train_images = ((train_images / 255) * 2) -1\n",
    "#test_images = ((test_images / 255) * 2) -1\n",
    "\n",
    "#from tensorflow import convert_to_tensor\n",
    "#train_images=convert_to_tensor(train_images, dtype=tf.int64)\n",
    "#train_labels=convert_to_tensor(train_labels, dtype=tf.int64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwm1OFOtc4uU"
   },
   "source": [
    "# Defining the neural network architecture (i.e., the network model)\n",
    "Create a LeNet5-like convolutional neural network taking in input the images as matrices of pixels and suitable to classify each image across 10 different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pnd3q1V3nk8v",
    "outputId": "b722b803-6d3f-44f4-ca89-8c465e94f92e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 08:17:10.743093: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-08-27 08:17:10.743373: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-27 08:17:10.745058: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# The Sequential module is sort of a container for more complex NN elements and\n",
    "# defines a loop-less NN architecture\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Activation, Flatten\n",
    "#from keras.layers import Convolution2D, MaxPooling2D\n",
    "#from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2D\n",
    "\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (5, 5)\n",
    "# Number of filters in first convolutional layer\n",
    "num_kernel_first_conv_layer = 6\n",
    "# Number of filters in second convolutional layer\n",
    "num_kernel_second_conv_layer = 16\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer\n",
    "#model.add(Convolution2D(num_kernel_first_conv_layer, (kernel_size[0], kernel_size[1]), input_shape=input_shape, padding='same'))\n",
    "model.add(Conv2D(num_kernel_first_conv_layer, (kernel_size[0], kernel_size[1]), input_shape=input_shape, padding='same'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Second convolutional layer\n",
    "#model.add(Convolution2D(num_kernel_second_conv_layer, (kernel_size[0], kernel_size[1]), padding='same'))\n",
    "model.add(Conv2D(num_kernel_second_conv_layer, (kernel_size[0], kernel_size[1]), padding='same'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Turns the sequence of featuremaps into a linear array of features\n",
    "model.add(Flatten())\n",
    "\n",
    "# Simplified LeNet5 configuration\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_F7zfhY9NJw"
   },
   "source": [
    "Instantiate a SGD optimizer with a tentative LR of 10^-2 and using the appropriate loss function and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "PoecwIXr9PZf",
    "outputId": "42df804c-f8df-446f-cb99-2fc02c089ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        2416      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 82,082\n",
      "Trainable params: 82,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The optimizers module provides a number of optimization algorithms for updating\n",
    "# a netwok parameters accoridng to the computed error gradints\n",
    "#from keras import optimizers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Defining our optimizer\n",
    "optimizer=tf.optimizers.SGD(learning_rate=1e-2)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Let us have a look at the model topology\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AWUAW4idF3D"
   },
   "source": [
    "# Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8evi8ZN9tcb",
    "outputId": "fc53306a-cede-4410-b8e5-871a4c489eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 08:17:11.167546: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2024-08-27 08:17:11.167895: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2599990000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "937/937 [==============================] - 336s 357ms/step - loss: 2.3116 - accuracy: 0.1071 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
      "Epoch 2/20\n",
      "937/937 [==============================] - 320s 342ms/step - loss: 2.2989 - accuracy: 0.1178 - val_loss: 2.2967 - val_accuracy: 0.1108\n",
      "Epoch 3/20\n",
      "937/937 [==============================] - 376s 401ms/step - loss: 2.2924 - accuracy: 0.1292 - val_loss: 2.2895 - val_accuracy: 0.1466\n",
      "Epoch 4/20\n",
      "937/937 [==============================] - 324s 346ms/step - loss: 2.2732 - accuracy: 0.1849 - val_loss: 2.2619 - val_accuracy: 0.2067\n",
      "Epoch 5/20\n",
      "937/937 [==============================] - 281s 299ms/step - loss: 2.1955 - accuracy: 0.3946 - val_loss: 2.1139 - val_accuracy: 0.3187\n",
      "Epoch 6/20\n",
      "937/937 [==============================] - 304s 325ms/step - loss: 1.8801 - accuracy: 0.5487 - val_loss: 1.9016 - val_accuracy: 0.3867\n",
      "Epoch 7/20\n",
      "937/937 [==============================] - 290s 310ms/step - loss: 1.3841 - accuracy: 0.6551 - val_loss: 1.7699 - val_accuracy: 0.4190\n",
      "Epoch 8/20\n",
      "937/937 [==============================] - 284s 303ms/step - loss: 1.0541 - accuracy: 0.7212 - val_loss: 1.7019 - val_accuracy: 0.4548\n",
      "Epoch 9/20\n",
      "937/937 [==============================] - 317s 338ms/step - loss: 0.8761 - accuracy: 0.7573 - val_loss: 1.6963 - val_accuracy: 0.4618\n",
      "Epoch 10/20\n",
      "937/937 [==============================] - 344s 367ms/step - loss: 0.7638 - accuracy: 0.7851 - val_loss: 1.6908 - val_accuracy: 0.4810\n",
      "Epoch 11/20\n",
      "937/937 [==============================] - 302s 323ms/step - loss: 0.6796 - accuracy: 0.8073 - val_loss: 1.6696 - val_accuracy: 0.5036\n",
      "Epoch 12/20\n",
      "937/937 [==============================] - 351s 374ms/step - loss: 0.6199 - accuracy: 0.8230 - val_loss: 1.7235 - val_accuracy: 0.4960\n",
      "Epoch 13/20\n",
      "937/937 [==============================] - 374s 398ms/step - loss: 0.5613 - accuracy: 0.8383 - val_loss: 1.8039 - val_accuracy: 0.4903\n",
      "Epoch 14/20\n",
      "937/937 [==============================] - 373s 398ms/step - loss: 0.5189 - accuracy: 0.8536 - val_loss: 1.6828 - val_accuracy: 0.5172\n",
      "Epoch 15/20\n",
      "937/937 [==============================] - 312s 332ms/step - loss: 0.4888 - accuracy: 0.8584 - val_loss: 1.7416 - val_accuracy: 0.5091\n",
      "Epoch 16/20\n",
      "937/937 [==============================] - 281s 300ms/step - loss: 0.4530 - accuracy: 0.8690 - val_loss: 1.7506 - val_accuracy: 0.5213\n",
      "Epoch 17/20\n",
      "937/937 [==============================] - 1959s 2s/step - loss: 0.4278 - accuracy: 0.8772 - val_loss: 1.6999 - val_accuracy: 0.5349\n",
      "Epoch 18/20\n",
      "851/937 [==========================>...] - ETA: 30s - loss: 0.4010 - accuracy: 0.8835"
     ]
    }
   ],
   "source": [
    "#Doing data augmentation with ImagDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Definir os parâmetros\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=10, # Rotating randomly the images up to 25°\n",
    "    width_shift_range=0.05, # Moving the images from left to right\n",
    "    height_shift_range=0.05, # Then from top to bottom\n",
    "    shear_range=0.10,\n",
    "    zoom_range=0.05, # Zooming randomly up to 20%\n",
    "    zca_whitening=False,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "\n",
    "print(len(train_images)//BATCH_SIZE)\n",
    "\n",
    "# Creating a data generator to augment the training images\n",
    "train_generator = augmenter.flow(train_images, train_labels, batch_size=BATCH_SIZE)\n",
    "\n",
    "batch_history =model.fit(train_generator, steps_per_epoch=(len(train_images)//BATCH_SIZE),\n",
    "                         validation_data=(test_images, test_labels),epochs=EPOCHS)\n",
    "\n",
    "result = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891
    },
    "id": "eNhBimFB7O-K",
    "outputId": "6e3b0157-e22a-4eb9-c318-90b34ef799e9"
   },
   "outputs": [],
   "source": [
    "# We now want to plot the train and validation loss functions and accuracy curves\n",
    "#print(history.history.keys())\n",
    "\n",
    "print(f'Test accuracy: {result[1]}')\n",
    "\n",
    "\n",
    "# Plot the loss function and accuracy\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "# Loss\n",
    "axs[0].plot(batch_history.history['loss'], label='Perda de Treinamento')\n",
    "axs[0].plot(batch_history.history['val_loss'], label='Perda de Validação')\n",
    "axs[0].set_title('Função de Perda/ Model Loss')\n",
    "axs[0].set_xlabel('Épocas/Epoch')\n",
    "axs[0].set_ylabel('Perda/Loss')\n",
    "axs[0].legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "# Accuracy\n",
    "axs[1].plot(batch_history.history['accuracy'], label='Acurácia de Treinamento')\n",
    "axs[1].plot(batch_history.history['val_accuracy'], label='Acurácia de Validação')\n",
    "axs[1].set_title('Acurácia/Accuracy')\n",
    "axs[1].set_xlabel('Épocas/Epoch')\n",
    "axs[1].set_ylabel('Acurácia/Accuracy')\n",
    "axs[1].legend(['train', 'test'], loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODUc5Bq_dMEq"
   },
   "source": [
    "# Visualizing the network performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "QdJrRbyariEw",
    "outputId": "48068e30-a0d7-4e6e-da0c-b159e70e594b"
   },
   "outputs": [],
   "source": [
    "# We now want to plot the train and validation loss functions and accuracy curves\n",
    "#print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(batch_history.history['loss'])\n",
    "plt.plot(batch_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(batch_history.history['accuracy'])\n",
    "plt.plot(batch_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr4TdWoEoDzi"
   },
   "source": [
    "# Experiments\n",
    "\n",
    "Note down the performance of the trained network in terms of training and validation accuracy as a reference. Then, experiment as follow and compare performance with the reference scenario.\n",
    "\n",
    "*   **Filter size**: experiment with square filters of different size and compare performance with reference scenario.\n",
    "*   **Number of filters**: experiment increasing the number of filters in the first and second layer and find the maximum number of filters the network can tolerate before overfitting to the training samples.\n",
    "* **Padding**: experiment withnarrow and wide convolutions: what changes in terms of featuremap size ?\n",
    "*  **Pooling layers**: expeirment with different pooling layers (maxpooling and avgpooling): which one yield the best performance ?\n",
    "What happens if the pooling layers are removed altogether in terms of comlexity-performance tradeoff ?\n",
    "* **Pooling-less architectures**: Modify the network architecture to obtain a twofold reduction of each featuremap without resorting to pooling layers (hint: take insipiration from the ResNet architecture).\n",
    "* **Confusion analysis**: Using the proper metric  from sklearn, check which character is most frequently confused with which: can you explain why ?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r0C1J6R1Elfc",
    "outputId": "2470ca1e-48e3-4816-e873-0c6280a3ef24"
   },
   "outputs": [],
   "source": [
    "# Example of a confusion matrix using sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "predictions = model.predict(test_images)\n",
    "# Mind that confusion_matrix requires\n",
    "matrix = confusion_matrix(test_labels.argmax(axis=1), predictions.argmax(axis=1))\n",
    "print (matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IOI6Tl1dS13"
   },
   "source": [
    "#Saving the training results\n",
    "\n",
    "Save the best trained model (topology, parameters), and all the related side information required to deploy the trained model later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M68i9PeDdZrG",
    "outputId": "cebadd26-d235-4f63-dc4a-97b6ecff6f67"
   },
   "outputs": [],
   "source": [
    "# Create a directory for saving both the trained model and side information\n",
    "import os\n",
    "save_dir = os.path.join(os.getcwd(), 'trained_lenet5_mnist')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Save model and weights\n",
    "\n",
    "model_name = 'model.keras'\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Saving mean and standard deviation information as a CSV file\n",
    "import csv\n",
    "model_name = 'std_dev.csv'\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "w = csv.writer(open(model_path, \"w\"))\n",
    "dict={}\n",
    "dict['mean'] = train_mean\n",
    "dict['std'] = train_std\n",
    "for key, val in dict.items():\n",
    "    w.writerow([key, val])\n",
    "print('Saved side information at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "id": "_tTTRlr4M5UI",
    "outputId": "c383d75b-9803-482b-be0b-c400de6acaee"
   },
   "outputs": [],
   "source": [
    "# Figure size\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "datas = pd.DataFrame(ori_test_labels,columns=['label'])\n",
    "\n",
    "print(datas)\n",
    "print(ori_test_labels)\n",
    "\n",
    "# Countplot\n",
    "sns.countplot(x='label', data=datas)\n",
    "plt.title('Distribution of labels in training set')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
